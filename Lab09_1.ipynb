{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab09_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPulGf+hdy+5lq5nisL3tuT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danbom/tensorflow/blob/master/Lab09_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BC8a9u534cbw"
      },
      "source": [
        "## Lab 09 XOR - Logistic Regression \n",
        "- XOR 문제 Logistic Regression 으로 해결하기\n",
        "\n",
        "기본 Library 선언"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vmRmeTi4XhC"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.random.set_seed(777)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zC_0dTaw5Esi"
      },
      "source": [
        "x_data = [[0, 0],\n",
        "          [0, 1],\n",
        "          [1, 0],\n",
        "          [1, 1]]\n",
        "y_data = [[0],\n",
        "          [1],\n",
        "          [1],\n",
        "          [0]]\n",
        "\n",
        "plt.scatter(x_data[0][0], x_data[0][1], c='pink', marker='^')\n",
        "plt.scatter(x_data[3][0], x_data[3][1], c='pink', marker='^')\n",
        "plt.scatter(x_data[1][0], x_data[1][1], c='skyblue', marker='^')\n",
        "plt.scatter(x_data[2][0], x_data[2][1], c='skyblue', marker='^')\n",
        "\n",
        "plt.xlabel(\"x1\")\n",
        "plt.ylabel(\"x2\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PivdJQoE5_1T"
      },
      "source": [
        "XOR 처리 모델 만들기\n",
        "- Tensorflow data API를 통해 학습시킬 값들을 담는다. (Batch Size는 한번에 학습시킬 Size로 정한다.)\n",
        "- preprocess function 으로 features, labels 는 실재 학습에 쓰일 data 연산을 위해 integer -> float 으로 type를 맞춰준다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ledS3azb6D1u"
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((x_data, y_data)).batch(len(x_data))\n",
        "\n",
        "def preprocess_data(features, labels):\n",
        "    features = tf.cast(features, tf.float32)\n",
        "    labels = tf.cast(labels, tf.float32)\n",
        "    return features, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pyvOHRF6DJb"
      },
      "source": [
        "1) Logistic Regression 으로 XOR 모델 만들기\n",
        "\n",
        "- W = Weight / b = bias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Vb5UmTa7J7G"
      },
      "source": [
        "W = tf.Variable(tf.zeros((2,1)), name='weight')\n",
        "b = tf.Variable(tf.zeros((1,)), name = 'bias')\n",
        "print(\"W = {}, B = {}\".format(W.numpy(), b.numpy()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNfyLv8Z7kzn"
      },
      "source": [
        "Sigmoid 함수를 가설로 선언\n",
        "- Sigmoid 는 아래 그래프와 같이 0과 1의 값만 리턴 (tf.sigmoid(tf.matmul(X,W) + b)\n",
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAOQAAAAsCAYAAAB17BRUAAAFw0lEQVR4Ae3Y3a38NBCGcZdACZSARAFwzw2X3EEJlEAHUAIdQAfQAXQAHUAHoB//M9LISrLJfpzNObyWskkcezx+Mq/H2TFSQiAEQiAEQiAEQiAEQiAEQiAEQiAEQiAEQiAEQuAKAh+NMb68ol+6hEAI3JnAx2OMH8cYv97ZbsyFQAhcSeDzCPJKcukWAg8gEEE+AOp7Mumb5ruDE/pmjKFfynECEeRxZhd7+Cg/U0B+ssMfPv8yxhAQvfy8o29vX9e+hc7EoPw6+/mtCVJs+fbtxRzmP6bUPS0e/hljyBJnKXv8AUu7Dtccrp2HF3A0s56F1zP9eEuCnOND7Hw7xvh75d171uPr1ThbNc5U9vhjRftzcvr36f7orX8Ln7YqHnX2JO0F7W8n8WXLDQuHXdBS8d6XFmOxkH+Ql4gt1IHbAROx7eot5YcbMuwt477VvrKHQHfsWUSfOU+L91q2WxMkf8WEReeuRaoWrAw7Fzwg3S8FMucFfPX5fgpW9b7hnNkzqT9evGZXtlpaOdmtSZb9mmz5s7QqWa2sYg5jAty3p/WsbPUzu8Yqf/T7q3GotrJuF3nV5/y2CSztpvqMtgQpdique5+brg1YH63E0AvhCPBeBL+A5Yzi7HuthKxOG3WeCfDexr3D3rwX/Qmp7JSNuteWr7OP2hFTtaux1FchpJpj1fWzhYC/2vCt96127C4tBvX8DGcLj3lsHWefw2tzxGyLiWfarBWsK/bW2hyqlwErO/S0XUE6D1YBX4Nwdv5eq1VHcCvOxF2iIJCebQiAyLv41Zms8arM9+pnYGzM34vadDtlr5/NYRZ7f67/3VfDPsBJru1sznx8emdOYsOxVub4mtstxeTc5tA94clWczAS0Sw0hgmUEwrRCNIS3kv1f7b0rUxDfH3r61nvQ0R8qPbsEK9xqq7uawznWhyqjTrjzHPZI8hL4I21xKP78x6uzyxGvr1rQVYgE4Tg7xlyzmI92GRFfRxzBtVO4HpWhdgqO1bm7WMR0bxKzeMTWRc12+p6v7I9Z0O2+gJQftXZHNjptupZndncel7tnnn2XrzHrePsc3htfphtMfFMm7WC9Rxva2036wVhBSlhzoKsLDYPVhlyrq/BShQluGpfz41pS2lMzxRCI5oq6o1fC4Z6YIi8hF11BVNbNsxDqfFdA7oGVb9aWPR1vzQ343YfP4xyrl9z5vvWUcwved75XWr7yOfm4p04HuGT97r1KbIlSCzn/0KuZmGiHGFUQM7BZiB18wvUj5OeL21X2erfcO57ZiMM/dRXYVMfY1XgewG9EOjsj7ZE5F9e2dK9b9FZfOx2H9j1cs1BfY3l3tzmOWvPfi1g3a/3do3FvPN41hz5gnm9W3HyiCK2ZrEb++uXeBKvn7U4KR/EMN/uUioIBd/sjAHUVZsaUMB3IbkmiKUArj7zmc2l8bQDfB6z+uuz1M/Yffy1l9YXibLZ+6lbG8MzQl3zrey9lzOG5nupEMvM8FKf/vyrMcZPC8cXrZF3svTuWpObL8X1NcJ6ekxwYBbFUt3NhB5gQPBcm+EE6Jx1H+DiaUzuFSQmawvgPBlB7zgqYPYfLUi+EuQR3462n3nc5V5A2zZWppAhe8a8yyAPNNK3p0eGAb/mfKTfW217b0HibiEXK3sXRbxtE/ki5mwfH/0OLBhzwll6h3vbLfW9ex2HQXLscf7uDtxg0As9ujURQI8OhBum9JCuW4KUReyKHL69ZK+6X8owREhQOB5ZvDEX+Aq7df1SlVMI/H8IbAmyU9izZSXWvVmx2851CITACwHZiJAulT2CtF2VGWU8Qk8JgRA4SIBwHJe26jLf0ja1D8cGQUaMnUquQyAEQiAEQiAEQiAEQiAEQiAEQiAEQiAEQiAEQiAEQiAEQiAEQiAEQiAEQiAEQiAEQiAEQiAEQiAEQiAEQiAEQiAEQiAEQiAEQiAEQiAEQiAEQuBkBP4F2SlY+Sblyn4AAAAASUVORK5CYII=)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRzVAOkm75qp"
      },
      "source": [
        "def logistic_regression(features):\n",
        "    hypothesis = tf.divide(1.,1.+tf.exp(tf.matmul(features,W)+b))\n",
        "    return hypothesis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7bq_NFz8M1K"
      },
      "source": [
        "Cost 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H00PhARh8OU1"
      },
      "source": [
        "def loss_fn(hypothesis, features, labels):\n",
        "    cost = -tf.reduce_mean(labels * tf.math.log(logistic_regression(features))+(1-labels)*tf.math.log(1-hypothesis))\n",
        "    return cost\n",
        "\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nML-uL0O8mf2"
      },
      "source": [
        "추론한 값은 0.5를 기준으로 0과 1의 값을 리턴\n",
        "- Sigmoid 함수를 통해 예측값이 0.5보다 크면 1을 반환, 0.5보다 작으면 0을 반환"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIYQ7jwE8u3k"
      },
      "source": [
        "def accuracy_fn(hypothesis, labels):\n",
        "    predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
        "    accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, labels), dtype=tf.float32))\n",
        "    return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynHQ_Lk-9BYm"
      },
      "source": [
        "GradientTape 를 통해 경사값 계산"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3sojfLl9EV9"
      },
      "source": [
        "def grad(hypothesis, features, labels):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss_value = loss_fn(logistic_regression(features),features, labels)\n",
        "    return tape.gradient(loss_value, [W,b])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "am-5M0409avy"
      },
      "source": [
        "실행\n",
        "- 위의 Data를 Cost 함수를 통해 학습시킨 후 모델 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bi8RGh9Z9ftU"
      },
      "source": [
        "EPOCHS = 1001\n",
        "\n",
        "for step in range(EPOCHS):\n",
        "    for features, labels in dataset:\n",
        "        features, labels = preprocess_data(features, labels)\n",
        "        grads = grad(logistic_regression(features), features, labels)\n",
        "        optimizer.apply_gradients(grads_and_vars=zip(grads,[W,b]))\n",
        "        if step % 100 == 0:\n",
        "            print(\"Iter: {}, Loss: {: .4f}\".format(step, loss_fn(logistic_regression(features), features, labels)))\n",
        "print(\"W = {}, B = {}\".format(W.numpy(), b.numpy()))\n",
        "x_data, y_data = preprocess_data(x_data, y_data)\n",
        "test_acc = accuracy_fn(logistic_regression(x_data),y_data)\n",
        "print(\"Testset Accuracy: {: .4f}\".format(test_acc))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}